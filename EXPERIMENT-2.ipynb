{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2137af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/sanks04/anaconda3/lib/python3.11/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (4.65.0)\n",
      "Requirement already satisfied: keras in /Users/sanks04/anaconda3/lib/python3.11/site-packages (2.13.1)\n",
      "Requirement already satisfied: tensorflow in /Users/sanks04/anaconda3/lib/python3.11/site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install textblob\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f2e226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sanks04/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/sanks04/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Dropout\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import class_weight\n",
    "import sqlite3\n",
    "\n",
    "# Load Data\n",
    "conn = sqlite3.connect('database.sqlite')\n",
    "query = \"SELECT * FROM May2015 LIMIT 500000;\"  # Load a larger portion of your data\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words and word.isalpha()]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df = df.dropna(subset=['body'])\n",
    "df['body'] = df['body'].apply(preprocess_text)\n",
    "df = df[df['body'].str.len() > 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b8413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "df['polarity'] = df['body'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df['subjectivity'] = df['body'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "\n",
    "# Word2Vec Embeddings\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(df['body'])\n",
    "tfidf_dict = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))\n",
    "\n",
    "def get_average_word2vec(tokens_list, vector, tfidf_weights, k=300):\n",
    "    if len(tokens_list) < 1:\n",
    "        return np.zeros(k)\n",
    "    vectorized = [vector[word] * tfidf_weights.get(word, 1) if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "# Assuming you have the model path\n",
    "model_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "df['word2vec'] = df['body'].apply(lambda x: get_average_word2vec(x.split(), word2vec_model, tfidf_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4322c44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10298/10298 [==============================] - 5s 468us/step - loss: 0.6992 - accuracy: 0.5018 - val_loss: 0.7008 - val_accuracy: 0.0804\n",
      "Epoch 2/10\n",
      "10298/10298 [==============================] - 5s 446us/step - loss: 0.6932 - accuracy: 0.5060 - val_loss: 0.6983 - val_accuracy: 0.0804\n",
      "Epoch 3/10\n",
      "10298/10298 [==============================] - 5s 449us/step - loss: 0.6932 - accuracy: 0.4904 - val_loss: 0.6908 - val_accuracy: 0.9196\n",
      "Epoch 4/10\n",
      "10298/10298 [==============================] - 5s 446us/step - loss: 0.6932 - accuracy: 0.5102 - val_loss: 0.6972 - val_accuracy: 0.0804\n",
      "Epoch 5/10\n",
      "10298/10298 [==============================] - 5s 447us/step - loss: 0.6932 - accuracy: 0.4144 - val_loss: 0.6840 - val_accuracy: 0.9196\n",
      "Epoch 6/10\n",
      "10298/10298 [==============================] - 5s 448us/step - loss: 0.6932 - accuracy: 0.5460 - val_loss: 0.7001 - val_accuracy: 0.0804\n",
      "Epoch 7/10\n",
      "10298/10298 [==============================] - 5s 449us/step - loss: 0.6932 - accuracy: 0.5424 - val_loss: 0.7040 - val_accuracy: 0.0804\n",
      "Epoch 8/10\n",
      "10298/10298 [==============================] - 5s 448us/step - loss: 0.6932 - accuracy: 0.4219 - val_loss: 0.6842 - val_accuracy: 0.9196\n",
      "Epoch 9/10\n",
      "10298/10298 [==============================] - 5s 446us/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6823 - val_accuracy: 0.9196\n",
      "Epoch 10/10\n",
      "10298/10298 [==============================] - 5s 450us/step - loss: 0.6932 - accuracy: 0.5191 - val_loss: 0.6934 - val_accuracy: 0.0804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x417bc10d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = df['score'].apply(lambda x: 1 if x > 0 else 0)\n",
    "X = df[['polarity', 'subjectivity']]  # Include Word2Vec embeddings as needed\n",
    "y = df['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "# Neural Network Model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_dim=X.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), class_weight=class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "843ca3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2575/2575 [==============================] - 1s 180us/step\n",
      "Accuracy: 0.0804331200912854\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      1.00      0.15      6626\n",
      "           1       0.00      0.00      0.00     75753\n",
      "\n",
      "    accuracy                           0.08     82379\n",
      "   macro avg       0.04      0.50      0.07     82379\n",
      "weighted avg       0.01      0.08      0.01     82379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanks04/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanks04/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanks04/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb16a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(polarity, subjectivity):\n",
    "    input_data = np.array([[polarity, subjectivity]])\n",
    "    prediction = model.predict(input_data)\n",
    "    result = \"Positive\" if prediction >= 0.5 else \"Negative\"\n",
    "    return result\n",
    "\n",
    "result = predict_sentiment(-0.5, 0.5)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
