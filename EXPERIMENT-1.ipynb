{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f8e4778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/sanks04/anaconda3/lib/python3.11/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (4.65.0)\n",
      "Requirement already satisfied: keras in /Users/sanks04/anaconda3/lib/python3.11/site-packages (2.13.1)\n",
      "Requirement already satisfied: tensorflow in /Users/sanks04/anaconda3/lib/python3.11/site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/sanks04/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install textblob\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d316c",
   "metadata": {},
   "source": [
    "DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc9271c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('database.sqlite')\n",
    "\n",
    "# Load the data from the 'May2015' table\n",
    "query = \"SELECT * FROM May2015 LIMIT 100000;\"  # Loading 10,000 records as an example\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98577107",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ef4f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Download necessary nltk resources (only need to run once)\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Initialize stopwords and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    words = [stemmer.stem(word) for word in words if word not in stop_words and word.isalpha()]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Preprocessing steps\n",
    "df = df.dropna(subset=['body'])  # Drop rows with missing comment text\n",
    "df['body'] = df['body'].apply(preprocess_text)  # Preprocess text\n",
    "df = df[df['body'].str.len() > 10]  # Filter out comments that are too short\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff33ba7d",
   "metadata": {},
   "source": [
    "3. Feature Engineering\n",
    "\n",
    "Sentiment Analysis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4939526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity'] = df['body'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df['subjectivity'] = df['body'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75672eae",
   "metadata": {},
   "source": [
    "Word2Vec Embeddings:\n",
    "Load the model and get embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e97037fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(df['body'])\n",
    "tfidf_dict = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))\n",
    "\n",
    "def get_average_word2vec(tokens_list, vector, tfidf_weights, k=300):\n",
    "    if len(tokens_list) < 1:\n",
    "        return np.zeros(k)\n",
    "    vectorized = [vector[word] * tfidf_weights.get(word, 1) if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "# Load Word2Vec model\n",
    "model_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "\n",
    "df['word2vec'] = df['body'].apply(lambda x: get_average_word2vec(x.split(), word2vec_model, tfidf_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50c105",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "556da997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2014/2014 [==============================] - 1s 472us/step - loss: 0.6921 - accuracy: 0.5681 - val_loss: 0.6923 - val_accuracy: 0.5619\n",
      "Epoch 2/10\n",
      "2014/2014 [==============================] - 1s 447us/step - loss: 0.6913 - accuracy: 0.5648 - val_loss: 0.6528 - val_accuracy: 0.7684\n",
      "Epoch 3/10\n",
      "2014/2014 [==============================] - 1s 449us/step - loss: 0.6914 - accuracy: 0.6485 - val_loss: 0.7288 - val_accuracy: 0.4560\n",
      "Epoch 4/10\n",
      "2014/2014 [==============================] - 1s 449us/step - loss: 0.6913 - accuracy: 0.6038 - val_loss: 0.7082 - val_accuracy: 0.5057\n",
      "Epoch 5/10\n",
      "2014/2014 [==============================] - 1s 450us/step - loss: 0.6913 - accuracy: 0.6031 - val_loss: 0.6901 - val_accuracy: 0.6556\n",
      "Epoch 6/10\n",
      "2014/2014 [==============================] - 1s 449us/step - loss: 0.6910 - accuracy: 0.6391 - val_loss: 0.6952 - val_accuracy: 0.6390\n",
      "Epoch 7/10\n",
      "2014/2014 [==============================] - 1s 447us/step - loss: 0.6911 - accuracy: 0.6299 - val_loss: 0.7048 - val_accuracy: 0.5498\n",
      "Epoch 8/10\n",
      "2014/2014 [==============================] - 1s 446us/step - loss: 0.6908 - accuracy: 0.6171 - val_loss: 0.6847 - val_accuracy: 0.6960\n",
      "Epoch 9/10\n",
      "2014/2014 [==============================] - 1s 447us/step - loss: 0.6910 - accuracy: 0.6173 - val_loss: 0.6611 - val_accuracy: 0.7463\n",
      "Epoch 10/10\n",
      "2014/2014 [==============================] - 1s 446us/step - loss: 0.6914 - accuracy: 0.6179 - val_loss: 0.6876 - val_accuracy: 0.6813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3ce789690>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = df['score'].apply(lambda x: 1 if x > 0 else 0)\n",
    "X = df[['polarity', 'subjectivity']]  # You can add other columns if needed\n",
    "y = df['target'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', \n",
    "                                                  classes=[0, 1], \n",
    "                                                  y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_dim=X.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), class_weight=class_weights_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4317d627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504/504 [==============================] - 0s 222us/step - loss: 0.6876 - accuracy: 0.6813\n",
      "Loss: 0.6875523328781128, Accuracy: 0.6812565922737122\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c962dd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504/504 [==============================] - 0s 188us/step\n",
      "Accuracy: 0.6812565965108338\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.33      0.14      1222\n",
      "           1       0.93      0.71      0.80     14885\n",
      "\n",
      "    accuracy                           0.68     16107\n",
      "   macro avg       0.51      0.52      0.47     16107\n",
      "weighted avg       0.86      0.68      0.75     16107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = [1 if p >= 0.5 else 0 for p in y_pred]  # Converting probabilities to binary labels\n",
    "\n",
    "# Computing evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08d55c61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/sanks04/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/sanks04/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/sanks04/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/sanks04/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"/Users/sanks04/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/sanks04/anaconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 2), found shape=(None, 4)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Predict using the fixed function\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m result_fixed \u001b[38;5;241m=\u001b[39m predict_sentiment_fixed(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m                                     )\n\u001b[1;32m     16\u001b[0m result_fixed\n",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m, in \u001b[0;36mpredict_sentiment_fixed\u001b[0;34m(polarity, subjectivity, ups, controversiality)\u001b[0m\n\u001b[1;32m      3\u001b[0m input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[polarity, subjectivity, ups, controversiality]])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get model prediction\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(input_data)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert probability to binary label\u001b[39;00m\n\u001b[1;32m      9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/84/q28xq9qj34l95x799pt_fntr0000gn/T/__autograph_generated_file9387s5f6.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/sanks04/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/sanks04/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/sanks04/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/sanks04/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"/Users/sanks04/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/sanks04/anaconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 2), found shape=(None, 4)\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment_fixed(polarity, subjectivity, ups, controversiality):\n",
    "    # Prepare the input data\n",
    "    input_data = np.array([[polarity, subjectivity, ups, controversiality]])\n",
    "    \n",
    "    # Get model prediction\n",
    "    prediction = model.predict(input_data)\n",
    "    \n",
    "    # Convert probability to binary label\n",
    "    result = \"Positive\" if prediction >= 0.5 else \"Negative\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Predict using the fixed function\n",
    "result_fixed = predict_sentiment_fixed(-5, 5, 5, 1\n",
    "                                    )\n",
    "result_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af9f3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
